{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0WNVb19-1Vy"
      },
      "source": [
        "# Programming Project #2: Image Quilting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIkgcR4l-1V1"
      },
      "source": [
        "## CS445: Computational Photography - Fall 2020\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j23xdf6pFUbC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Trc-kktC-1V4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "# modify to where you store your project data including utils.py\n",
        "datadir = \"/content/drive/My Drive/CS 180/cs180_final_proj/\"\n",
        "\n",
        "utilfn = datadir + \"utils.py\"\n",
        "!cp \"$utilfn\" .\n",
        "samplesfn = datadir + \"samples\"\n",
        "!cp -r \"$samplesfn\" .\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "962rNeOU-1WA"
      },
      "outputs": [],
      "source": [
        "from utils import cut # default cut function for seam finding section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8viLMXxu-1WH"
      },
      "source": [
        "### Part I: Randomly Sampled Texture (10 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7ASHXPhqri7"
      },
      "outputs": [],
      "source": [
        "# sample patches randomly\n",
        "def img_random_sample(sample, patch_size):\n",
        "    image_size = sample.shape\n",
        "    x1 = random.randint(0, image_size[0]-patch_size-1)\n",
        "    y1 = random.randint(0, image_size[1]-patch_size-1)\n",
        "    x2, y2 = x1+patch_size, y1+patch_size\n",
        "\n",
        "    patch = sample[x1:x2, y1:y2, :]\n",
        "    return patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9GeLMBe-1WP"
      },
      "outputs": [],
      "source": [
        "def quilt_random(sample, out_size, patch_size):\n",
        "    \"\"\"\n",
        "    Randomly samples square patches of size patchsize from sample in order to create an output image of size outsize.\n",
        "\n",
        "    :param sample: numpy.ndarray   The image you read from sample directory\n",
        "    :param out_size: int            The width of the square output image\n",
        "    :param patch_size: int          The width of the square sample patch\n",
        "    :return: numpy.ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    num_patch_samples = out_size // patch_size\n",
        "    out_img = np.zeros((out_size, out_size, 3))\n",
        "\n",
        "    for i in range(num_patch_samples):\n",
        "      for j in range(num_patch_samples):\n",
        "        patch = img_random_sample(sample, patch_size)\n",
        "        out_img[i*patch_size : (i+1) * patch_size, j*patch_size : (j+1) * patch_size, :] = patch/255.0\n",
        "\n",
        "    return out_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOTP1KWS-1WU"
      },
      "outputs": [],
      "source": [
        "sample_img_fn = 'samples/bricks_small.jpg' # feel free to change\n",
        "sample_img = cv2.cvtColor(cv2.imread(sample_img_fn), cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(sample_img)\n",
        "plt.savefig('method_1_original.jpeg', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "for i in range(1,3):\n",
        "  out_size = 200  # change these parameters as needed\n",
        "  patch_size = 15\n",
        "  res = quilt_random(sample_img, out_size, patch_size)\n",
        "\n",
        "  if res is not None:\n",
        "      plt.imshow(res)\n",
        "      plt.title('Method 1 (Randomly Sampled Texture), Run '+str(i))\n",
        "      plt.savefig('method_1_sample_'+str(i)+'.jpeg', bbox_inches='tight')\n",
        "      plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbWYx0Zu-1WZ"
      },
      "source": [
        "### Part II: Overlapping Patches (30 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbQvBriMyuyT"
      },
      "source": [
        "Create a function quilt_simple(sample, out_size, patch_size, overlap, tol) that randomly samples square patches of size patch_size from a sample in order to create an output image of size out_size. Start by sampling a random patch for the upper-left corner. Then sample new patches to overlap with existing ones. For example, the second patch along the top row will overlap by patch_size pixels in the vertical direction and overlap pixels in the horizontal direction. Patches in the first column will overlap by patch_size pixels in the horizontal direction and overlap pixels in the vertical direction. Other patches will have two overlapping regions (on the top and left) which should both be taken into account. Once the cost of each patch has been computed, randomly choose on patch whose cost is less than a threshold determined by tol (see description of choose_sample below).\n",
        "\n",
        "After a patch is sampled, its pixels should be copied directly into the corresponding position in the output image. Note that it is very easy to make alignment mistakes when computing the cost of each patch, sampling a low-cost patch, and copying the patch from the source to the output. Use an odd value for patch_size so that its center is well-defined. Be sure to thoroughly debug, for example, by checking that the overlapping portion of the copied pixels has the same SSD as the originally computed cost. As a sanity check, try generating a small texture image with tol=1, with the first patch sampled from the upper-left of the source image. This should produce a partial copy of the source image. Once you have this function working, save a result (with higher tolerance for more stochastic texture) generated from the same sample as used for the random method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tnMbAdpzfrc"
      },
      "source": [
        "`ssd_patch` performs template matching with the overlapping region, computing the cost of sampling each patch, based on the sum of squared differences (SSD) of the overlapping regions of the existing and sampled patch. I suggest using a masked template. The template is the patch in the current output image that is to be filled in (many pixel values will be 0 because they are not filled in yet). The mask has the same size as the patch template and has values of 1 in the overlapping region and values of 0 elsewhere. The SSD of the masked template with the input texture image can be computed efficiently using filtering operations. Suppose I have a template T, a mask M, and an image I: then, ssd_cost = ((M*T)**2).sum() - 2 * cv2.filter2D(I, ddepth=-1, kernel = M*T) + cv2.filter2D(I ** 2, ddepth=-1, kernel=M). You can compute SSD in this way for each channel and sum the costs over channels. Each pixel of the ssd_cost gives you the cost for sampling a patch centered around that pixel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1i3E_yrzavo"
      },
      "source": [
        "`choose_sample` should take as input a cost image (each pixel's value is the cost of selecting the patch centered at that pixel) and select a randomly sampled patch with low cost. It's recommended to sort the costs and choose of of the tol smallest costs. So if tol=1, the lowest cost will always be chosen (this is a good way to debug but mainly copies the input texture). If tol=3, one of the three lowest cost patches will be chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv9fpLxvqRXe"
      },
      "outputs": [],
      "source": [
        "def ssd_patch(output, patch_coords, patch):\n",
        "    \"\"\"\n",
        "    Find SSD between selected patch from sample and\n",
        "    output: output image\n",
        "    patch_coords: (i,j) upper left coordinates of patch\n",
        "    patch: selected patch from texture image (sample)\n",
        "    \"\"\"\n",
        "    uY, uX = patch_coords\n",
        "    output_patch = output[uY : uY + patch.shape[0], uX : uX + patch.shape[1], :]\n",
        "    mask = output_patch.copy()\n",
        "    mask[mask > 0] = 1\n",
        "    maskedPatch = patch.copy() * mask\n",
        "    diff = output_patch - maskedPatch\n",
        "    return np.sum(diff ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_wPVwEJB4q6"
      },
      "outputs": [],
      "source": [
        "def choose_sample(cost_image, tol):\n",
        "    # flatten cost image and sort\n",
        "    flat_costs = cost_image.ravel()\n",
        "    sorted_indices = np.argsort(flat_costs)\n",
        "\n",
        "    random_tol = np.random.randint(tol)\n",
        "    # print(\"random tol\", random_tol)\n",
        "    chosen_index = sorted_indices[random_tol]\n",
        "    chosen_row = chosen_index // cost_image.shape[1]\n",
        "    chosen_col = chosen_index % cost_image.shape[1]\n",
        "\n",
        "    # print(chosen_row, chosen_col)\n",
        "\n",
        "    return chosen_row, chosen_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haF4w8E0qTN_"
      },
      "outputs": [],
      "source": [
        "def quilt_simple(sample, out_size, patch_size, overlap, tol):\n",
        "    \"\"\"\n",
        "    Create a quilted image from a sample by randomly sampling patches.\n",
        "\n",
        "    :param sample: Source image from which patches are sampled.\n",
        "    :param out_size: Size of the output image.\n",
        "    :param patch_size: Size of each patch.\n",
        "    :param overlap: Overlap size between patches.\n",
        "    :param tol: Tolerance for choosing patches based on SSD cost.\n",
        "    :return: Quilted image.\n",
        "    \"\"\"\n",
        "    output = np.zeros((out_size, out_size, sample.shape[2]), dtype=sample.dtype)\n",
        "\n",
        "    for i in range(0, out_size - patch_size, patch_size - overlap):\n",
        "        for j in range(0, out_size - patch_size, patch_size - overlap):\n",
        "            matrix = np.zeros((sample.shape[0] - patch_size, sample.shape[1] - patch_size))\n",
        "            for y in range(matrix.shape[0]):\n",
        "              for x in range(matrix.shape[1]):\n",
        "                patch = sample[y:y+patch_size, x:x+patch_size]\n",
        "                matrix[y,x] = ssd_patch(output, (i,j), patch)\n",
        "            uY, uX = choose_sample(matrix, tol)\n",
        "            patch_chosen = sample[uY:uY+patch_size, uX:uX+patch_size]\n",
        "            output[i:i+patch_size,j:j+patch_size] = patch_chosen\n",
        "    return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1BfaV8eqWY4"
      },
      "outputs": [],
      "source": [
        "sample_img_fn = 'samples/bricks_small.jpg'\n",
        "sample_img = cv2.cvtColor(cv2.imread(sample_img_fn), cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(sample_img)\n",
        "plt.show()\n",
        "\n",
        "tol_lst = [5,10,15]\n",
        "\n",
        "for i in tol_lst:\n",
        "  out_size = 300  # change these parameters as needed\n",
        "  patch_size = 50\n",
        "  overlap = 20\n",
        "  tol = i\n",
        "\n",
        "  res = quilt_simple(sample_img, out_size, patch_size, overlap, tol) #feel free to change parameters to get best results\n",
        "  if res is not None:\n",
        "      plt.figure(figsize=(10,10))\n",
        "      plt.title('Method 2 (Overlapping Patches), tol = '+str(i))\n",
        "      plt.imshow(res)\n",
        "      plt.savefig('method_2_tol_'+str(i)+'.jpeg', bbox_inches='tight')\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpXmkNvw-1Wm"
      },
      "source": [
        "### Part III: Seam Finding (20 pts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-qqL9x8wEto"
      },
      "source": [
        "Use the cut function in utils.py (download starter_codes at the top) that finds the min-cost contiguous path from the left to right side of the patch according to the cost indicated by bndcost. The cost of a path through each pixel is the square differences (summed over RGB for color images) of the output image and the newly sampled patch. Note that if a patch has top and left overlaps, you will need to compute two seams and the mask can be defined as the intersection of the masks for each seam (np.logical_and(mask1,mask2)). To find a vertical path, you can apply cut to the transposed patch, e.g., cut(bndcost.T).T.\n",
        "\n",
        "Create a function quilt_cut that incorporates the seam finding and use it to create a result to compare to the previous two methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAepuWTT-1Wo"
      },
      "outputs": [],
      "source": [
        "def customized_cut(bndcost):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix-cBc7xxkA0"
      },
      "outputs": [],
      "source": [
        "def get_patch(sample, output, i, j, tol):\n",
        "      i_end = min(i + patch_size, out_size)\n",
        "      j_end = min(j + patch_size, out_size)\n",
        "      region = output[i:i_end, j:j_end]\n",
        "\n",
        "      mask = np.zeros_like(region)\n",
        "      if i > 0:\n",
        "          mask[:overlap, :] = 1  # overlap on top\n",
        "      if j > 0:\n",
        "          mask[:, :overlap] = 1  # overlap on left\n",
        "\n",
        "      ssd = ssd_patch(region, mask, sample)\n",
        "      print(ssd.shape)\n",
        "      patch_i, patch_j = choose_sample(ssd, tol)\n",
        "      patch_i = min(patch_i, sample.shape[0] - patch_size)\n",
        "      patch_j = min(patch_j, sample.shape[1] - patch_size)\n",
        "\n",
        "      patch = sample[patch_i:patch_i + patch_size, patch_j:patch_j + patch_size]\n",
        "      return patch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OPtXzDX_ejN"
      },
      "outputs": [],
      "source": [
        "def blend_patches(output, patch, mask, i, j, overlap):\n",
        "    blended_patch = np.copy(patch)\n",
        "\n",
        "    if i > 0:\n",
        "        for row in range(overlap):\n",
        "            for col in range(patch.shape[1]):\n",
        "                if mask[row, col]:\n",
        "                    blended_patch[row, col] = patch[row, col]\n",
        "                else:\n",
        "                    blended_patch[row, col] = output[i + row, j + col]\n",
        "\n",
        "    if j > 0:\n",
        "        for row in range(patch.shape[0]):\n",
        "            for col in range(overlap):\n",
        "                if mask[row, col]:\n",
        "                    blended_patch[row, col] = patch[row, col]\n",
        "                else:\n",
        "                    blended_patch[row, col] = output[i + row, j + col]\n",
        "\n",
        "    return blended_patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tbkrr11H_fNp"
      },
      "outputs": [],
      "source": [
        "def compute_boundary_cost(output, patch, i, j, overlap):\n",
        "    boundary_cost = np.zeros((patch.shape[0], patch.shape[1]))\n",
        "\n",
        "    if i > 0:\n",
        "        top_overlap_output = output[i:i + overlap, j:j + patch.shape[1]]\n",
        "        top_overlap_patch = patch[:overlap, :]\n",
        "        boundary_cost[:overlap, :] = np.sum((top_overlap_output - top_overlap_patch)**2, axis=2)\n",
        "\n",
        "    if j > 0:\n",
        "        left_overlap_output = output[i:i + patch.shape[0], j:j + overlap]\n",
        "        left_overlap_patch = patch[:, :overlap]\n",
        "        boundary_cost[:, :overlap] += np.sum((left_overlap_output - left_overlap_patch)**2, axis=2)\n",
        "\n",
        "    return boundary_cost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDOJnedG-War"
      },
      "outputs": [],
      "source": [
        "def quilt_cut(sample, out_size, patch_size, overlap, tol):\n",
        "    \"\"\"\n",
        "    Samples square patches of size patchsize from sample using seam finding in order to create an output image of size outsize.\n",
        "    Feel free to add function parameters\n",
        "    :param sample: numpy.ndarray\n",
        "    :param out_size: int\n",
        "    :param patch_size: int\n",
        "    :param overlap: int\n",
        "    :param tol: float\n",
        "    :return: numpy.ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    output = np.zeros((out_size, out_size, sample.shape[2]), dtype=sample.dtype)\n",
        "\n",
        "    for i in range(0, out_size - patch_size, patch_size - overlap):\n",
        "        for j in range(0, out_size - patch_size, patch_size - overlap):\n",
        "            matrix = np.zeros((sample.shape[0] - patch_size, sample.shape[1] - patch_size))\n",
        "            for y in range(matrix.shape[0]):\n",
        "              for x in range(matrix.shape[1]):\n",
        "                patch = sample[y:y+patch_size, x:x+patch_size]\n",
        "                matrix[y,x] = ssd_patch(output, (i,j), patch)\n",
        "            uY, uX = choose_sample(matrix, tol)\n",
        "            patch_chosen = sample[uY:uY+patch_size, uX:uX+patch_size]\n",
        "\n",
        "            if i > 0 or j > 0:\n",
        "                bndcost = compute_boundary_cost(output, patch_chosen, i, j, overlap)\n",
        "                if i > 0 and j > 0:\n",
        "                    mask1 = cut(bndcost)\n",
        "                    mask2 = cut(bndcost.T).T\n",
        "                    mask = np.logical_and(mask1, mask2)\n",
        "                elif i > 0:\n",
        "                    mask = cut(bndcost)\n",
        "                else:  # j > 0\n",
        "                    mask = cut(bndcost.T).T\n",
        "\n",
        "                patch = blend_patches(output, patch_chosen, mask, i, j, overlap)\n",
        "\n",
        "            output[i:i+patch_size,j:j+patch_size] = patch_chosen\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhEdl1MwIP_2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbnDy_F_-1Wy"
      },
      "outputs": [],
      "source": [
        "sample_img_fn = 'samples/bricks_small.jpg'\n",
        "sample_img = cv2.cvtColor(cv2.imread(sample_img_fn), cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(sample_img)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "out_size = 300  # change these parameters as needed\n",
        "patch_size = 50\n",
        "overlap = 20\n",
        "tol = 3\n",
        "\n",
        "\n",
        "res = quilt_cut(sample_img, out_size, patch_size, overlap, tol)\n",
        "if res is not None:\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.imshow(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggnAoVVt6nbT"
      },
      "outputs": [],
      "source": [
        "sample_img_fn = 'samples/texture.png'\n",
        "sample_img = cv2.cvtColor(cv2.imread(sample_img_fn), cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(sample_img)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "out_size = 600  # change these parameters as needed\n",
        "patch_size = 60\n",
        "overlap = 25\n",
        "tol = 3\n",
        "\n",
        "\n",
        "res = quilt_cut(sample_img, out_size, patch_size, overlap, tol)\n",
        "if res is not None:\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.imshow(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beM0Ryht-1W7"
      },
      "source": [
        "### part IV: Texture Transfer (30 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pmq-l7UBzBTI"
      },
      "outputs": [],
      "source": [
        "# def get_guidance_ssd(guidance_grey, texture_gray, i, j, guidance_patch_size, texture_patch_size):\n",
        "#     # source: guidance img\n",
        "#     guidance_ssd = np.zeros(source.shape[:2])\n",
        "#     target_region = target[i:i + patch_size, j:j + patch_size]\n",
        "#     for row in range(source.shape[0] - patch_size + 1):\n",
        "#         for col in range(source.shape[1] - patch_size + 1):\n",
        "#             source_patch = source[row:row + patch_size, col:col + patch_size]\n",
        "#             cost = np.sum((source_patch - target_region)**2)\n",
        "#             guidance_ssd[row, col] = cost\n",
        "#     return guidance_ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlRy0uxpuc2r"
      },
      "outputs": [],
      "source": [
        "# def ssd_patch(output, patch_coords, patch):\n",
        "#     \"\"\"\n",
        "#     Find SSD between selected patch from sample and\n",
        "#     output: output image\n",
        "#     patch_coords: (i,j) upper left coordinates of patch\n",
        "#     patch: selected patch from texture image (sample)\n",
        "#     \"\"\"\n",
        "#     uY, uX = patch_coords\n",
        "#     ROI = output[uY : uY + patch.shape[0], uX : uX + patch.shape[1], :]\n",
        "#     mask = ROI.copy()\n",
        "#     mask[mask > 0] = 1\n",
        "#     maskedPatch = patch.copy() * mask\n",
        "#     diff = ROI - maskedPatch\n",
        "#     return np.sum(diff ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viEJcYDks8gT"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "def texture_transfer(sample, patch_size, overlap, tol, guidance_im, alpha, texture_gray, guidance_gray,  guidance_gray_blurred, texture_gray_blurred):\n",
        "    \"\"\"\n",
        "    Samples square patches of size patchsize from sample using seam finding in order to create an output image of size outsize.\n",
        "    Feel free to modify function parameters\n",
        "    :param sample: numpy.ndarray\n",
        "    :param patch_size: int\n",
        "    :param overlap: int\n",
        "    :param tol: float\n",
        "    :param guidance_im: target overall appearance for the output\n",
        "    :param alpha: float 0-1 for strength of target\n",
        "    :return: numpy.ndarray\n",
        "    \"\"\"\n",
        "    assert guidance_im.shape[0] > sample.shape[0]\n",
        "\n",
        "    out_size = guidance_im.shape[:2]\n",
        "    output = np.zeros((out_size[0], out_size[1], sample.shape[2]), dtype=sample.dtype)\n",
        "\n",
        "    guidance_im = resize(guidance_im, (sample.shape[0] , sample.shape[1]),\n",
        "                       anti_aliasing=True)\n",
        "\n",
        "\n",
        "    for i in range(0, out_size[0] - patch_size - overlap, patch_size - overlap):\n",
        "        for j in range(0, out_size[1] - patch_size - overlap, patch_size - overlap):\n",
        "\n",
        "            ssd_matrix = np.zeros((guidance_im.shape[0] - patch_size, guidance_im.shape[1] - patch_size))\n",
        "            guidance_ssd_matrix = np.zeros((guidance_im.shape[0] - patch_size, guidance_im.shape[1] - patch_size))\n",
        "\n",
        "            for y in range(ssd_matrix.shape[0]):\n",
        "              for x in range(ssd_matrix.shape[1]):\n",
        "                target_patch = sample[y:y+patch_size, x:x+patch_size]\n",
        "                ssd_matrix[y,x] = ssd_patch(output, (i,j), target_patch)\n",
        "\n",
        "                grey_target_patch = guidance_gray[y:y+patch_size, x:x+patch_size]\n",
        "                grey_texture_patch = texture_gray[y:y+patch_size, x:x+patch_size]\n",
        "                grey_ssd = np.sum((grey_target_patch - grey_texture_patch) **2)\n",
        "\n",
        "                blurred_grey_target_patch = guidance_gray_blurred[y:y+patch_size, x:x+patch_size]\n",
        "                blurred_grey_texture_patch = texture_gray_blurred[y:y+patch_size, x:x+patch_size]\n",
        "                blurred_grey_ssd = np.sum((blurred_grey_target_patch - blurred_grey_texture_patch) **2)\n",
        "\n",
        "                guidance_ssd_matrix[y,x] = (0.5 * grey_ssd) + (0.5 * blurred_grey_ssd)\n",
        "\n",
        "            # # normalize\n",
        "            ssd_matrix = ssd_matrix / np.linalg.norm(ssd_matrix)\n",
        "            guidance_ssd_matrix = guidance_ssd_matrix/ np.linalg.norm(guidance_ssd_matrix)\n",
        "\n",
        "            combined_ssd_matrix = (alpha * ssd_matrix) + ((1-alpha) * guidance_ssd_matrix)\n",
        "            uY, uX = choose_sample(combined_ssd_matrix, tol)\n",
        "\n",
        "            patch_chosen = sample[uY:uY+patch_size, uX:uX+patch_size]\n",
        "\n",
        "            if i > 0 or j > 0:\n",
        "                bndcost = compute_boundary_cost(output, patch_chosen, i, j, overlap)\n",
        "                if i > 0 and j > 0:\n",
        "                    mask1 = cut(bndcost)\n",
        "                    mask2 = cut(bndcost.T).T\n",
        "                    mask = np.logical_and(mask1, mask2)\n",
        "                elif i > 0:\n",
        "                    mask = cut(bndcost)\n",
        "                else:  # j > 0\n",
        "                    mask = cut(bndcost.T).T\n",
        "\n",
        "                patch_chosen = blend_patches(output, patch_chosen, mask, i, j, overlap)\n",
        "\n",
        "            output[i:i+patch_size,j:j+patch_size] = patch_chosen\n",
        "        plt.imshow(output)\n",
        "        plt.show()\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "304kxcVubDMq"
      },
      "outputs": [],
      "source": [
        "# load/process appropriate input texture and guidance images\n",
        "texture_img_path = 'samples/sketch.tiff'\n",
        "guidance_img_path = 'samples/feynman.tiff'\n",
        "\n",
        "texture_img = cv2.cvtColor(cv2.imread(texture_img_path), cv2.COLOR_BGR2RGB)\n",
        "texture_img = cv2.resize(texture_img, (0,0), fx=0.75, fy=0.75)\n",
        "\n",
        "texture_gray = cv2.imread(texture_img_path,0)\n",
        "print(texture_gray.shape)\n",
        "texture_gray = cv2.resize(texture_gray, (0,0), fx=0.75, fy=0.75)\n",
        "texture_gray = cv2.normalize(texture_gray, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "texture_gray_blurred = cv2.GaussianBlur(texture_gray,(25,25),0)\n",
        "\n",
        "plt.imshow(texture_img)\n",
        "plt.show()\n",
        "\n",
        "guidance_img = cv2.cvtColor(cv2.imread(guidance_img_path), cv2.COLOR_BGR2RGB)\n",
        "guidance_gray = cv2.imread(guidance_img_path, 0)\n",
        "guidance_gray = cv2.normalize(guidance_gray, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "guidance_gray_blurred = cv2.GaussianBlur(guidance_gray,(25,25),0)\n",
        "\n",
        "\n",
        "\n",
        "plt.imshow(guidance_img)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "patch_size = 15\n",
        "overlap = 4\n",
        "tol = 1\n",
        "alpha = 0.1 #texture weight\n",
        "res = texture_transfer(texture_img, patch_size, overlap, tol, guidance_img, alpha, texture_gray, guidance_gray, guidance_gray_blurred, texture_gray_blurred)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(res)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YF4z5Pn-1XC"
      },
      "source": [
        "### Bells & Whistles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkyZmE5x-1XC"
      },
      "source": [
        "(10 pts) Create and use your own version of cut.m. To get these points, you should create your own implementation without basing it directly on the provided function (you're on the honor code for this one).\n",
        "\n",
        "You can simply copy your customized_cut(bndcost) into the box below so that it is easier for us to grade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_uu8QGV-1XD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKqN35Je-1XI"
      },
      "source": [
        "(15 pts) Implement the iterative texture transfer method described in the paper. Compare to the non-iterative method for two examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2E3ODng-1XJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJX7W1KY-1XN"
      },
      "source": [
        "(up to 20 pts) Use a combination of texture transfer and blending to create a face-in-toast image like the one on top. To get full points, you must use some type of blending, such as feathering or Laplacian pyramid blending."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDlsZWl_-1XO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnDruSHC-1XS"
      },
      "source": [
        "(up to 40 pts) Extend your method to fill holes of arbitrary shape for image completion. In this case, patches are drawn from other parts of the target image. For the full 40 pts, you should implement a smart priority function (e.g., similar to Criminisi et al.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8kJ9IOW-1XT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx3Ghbcg-1XX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0cXmR98-1Xc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNktu4lA-1Xg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}