{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFCezY5TsbSf"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install numpy pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuYyKqNoOQMh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzRHFbKSOSkb"
      },
      "outputs": [],
      "source": [
        "# load image as tf\n",
        "def load_img(path_to_img):\n",
        "    max_dim = 500\n",
        "    img = tf.io.read_file(path_to_img)\n",
        "    img = tf.image.decode_image(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "    long_dim = max(shape)\n",
        "    scale = max_dim / long_dim\n",
        "\n",
        "    new_shape = tf.cast(shape * scale, tf.int32)\n",
        "    img = tf.image.resize(img, new_shape)\n",
        "    img = img[tf.newaxis, :]\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and display images"
      ],
      "metadata": {
        "id": "Z6N7Vr54VKi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content_path = 'cat.jpg'\n",
        "style_path = 'starry_night.jpg'\n",
        "\n",
        "content_img = load_img(content_path)\n",
        "style_img = load_img(style_path)"
      ],
      "metadata": {
        "id": "A71eij5xVMon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(content_img[0])\n",
        "print(content_img.shape)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(style_img[0])\n",
        "print(style_img.shape)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8Xu6XwRHVMhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get layers from pretrained VGG model"
      ],
      "metadata": {
        "id": "_AcMKBeJNu5A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "151gOQBlyIol"
      },
      "outputs": [],
      "source": [
        "def get_vgg_layers(style_layers_names, content_layers_names):\n",
        "    # pretrained vgg cnn\n",
        "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', pooling='avg')\n",
        "    vgg.trainable = False\n",
        "    model_layers_names = style_layers_names + content_layers_names\n",
        "    model_outputs = [vgg.get_layer(name).output for name in model_layers_names]\n",
        "    return tf.keras.Model([vgg.input], model_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "style_layers_names = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "content_layers_names = ['block1_conv2', 'block2_conv2', 'block3_conv2']\n",
        "num_content_layers = len(content_layers_names)\n",
        "num_style_layers = len(style_layers_names)\n"
      ],
      "metadata": {
        "id": "i2c_rLIUOEgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArtisticCNN(tf.keras.models.Model):\n",
        "  def __init__(self, style_layers_names, content_layers_names):\n",
        "    super(ArtisticCNN, self).__init__()\n",
        "    self.vgg = get_vgg_layers(style_layers_names, content_layers_names)\n",
        "    self.style_layers = style_layers_names\n",
        "    self.content_layers = content_layers_names\n",
        "    self.vgg.trainable = False\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # make sure inputs are floats in [0,1]\n",
        "    # returns style outputs then content outputs\n",
        "    inputs = inputs * 255.0\n",
        "\n",
        "    input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
        "    all_outputs = self.vgg(input)\n",
        "\n",
        "    style_outputs = all_outputs[:num_style_layers]\n",
        "    style_outputs = [gram_matrix(style_output) for style_output in style_outputs]\n",
        "    content_outputs = all_outputs[num_style_layers:]\n",
        "\n",
        "    return style_outputs, content_outputs"
      ],
      "metadata": {
        "id": "6b3AU0KPN6Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ArtisticCNN(style_layers_names, content_layers_names)\n",
        "results = model(tf.constant(content_img))\n",
        "\n",
        "style_targets, _ = model(style_img)\n",
        "_, content_targets = model(content_img)"
      ],
      "metadata": {
        "id": "pNe3oh6suBS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.Variable(load_img(content_path)) #initialize with content photo\n",
        "\n",
        "epochs = 20\n",
        "steps_per_epoch = 50"
      ],
      "metadata": {
        "id": "ZWDPeo6Srdmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ64o-mpyQ2b"
      },
      "outputs": [],
      "source": [
        "# calculate gram matrix\n",
        "def gram_matrix(input_tensor):\n",
        "    channels = int(input_tensor.shape[-1])\n",
        "    a = tf.reshape(input_tensor, [-1, channels])\n",
        "    n = tf.shape(a)[0]\n",
        "    gram = tf.matmul(a, a, transpose_a=True)\n",
        "    num_locations = tf.cast(n, tf.float32)\n",
        "\n",
        "    return gram / num_locations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_loss(style_outputs, content_outputs):\n",
        "\n",
        "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[i]-style_targets[i])**2) for i in range(num_style_layers)])\n",
        "    style_loss *= style_weight / num_style_layers\n",
        "\n",
        "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[i]-content_targets[i])**2) for i in range(num_content_layers)])\n",
        "    content_loss *= content_weight / num_content_layers\n",
        "\n",
        "    loss = style_loss + content_loss\n",
        "    return loss"
      ],
      "metadata": {
        "id": "n_RrvkmSOdGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.2, beta_1=0.99, epsilon=1e-1)\n",
        "\n",
        "style_weight=1e-2\n",
        "content_weight=1e3\n"
      ],
      "metadata": {
        "id": "BZGdYlqwObXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.Variable(content_img) #initialize with content photo\n",
        "\n",
        "epochs = 20\n",
        "steps_per_epoch = 50"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lakdiocpkEnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step = 0\n",
        "for n in range(epochs):\n",
        "  plt.imshow(np.squeeze(image.read_value(), 0))\n",
        "  plt.title(\"Training epoch: {}\".format(n))\n",
        "  plt.savefig('cat_epoch'+str(n)+'.jpeg', bbox_inches='tight')\n",
        "  plt.show()\n",
        "\n",
        "  for m in range(steps_per_epoch):\n",
        "    step += 1\n",
        "    with tf.GradientTape() as tape:\n",
        "      style_outputs, content_outputs = model(image)\n",
        "      loss = get_total_loss(style_outputs, content_outputs)\n",
        "\n",
        "    grad = tape.gradient(loss, image)\n",
        "    opt.apply_gradients([(grad, image)])\n",
        "    clipped_image = tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "    image.assign(clipped_image)\n"
      ],
      "metadata": {
        "id": "dfkSlqijP9cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ff9cUcFB5UQJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}